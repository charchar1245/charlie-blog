<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>My First Steps Into Machine Learning</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="../style.css">

<style>
    body {
        max-width: 820px;
        margin: 40px auto;
        padding: 0 24px;
        line-height: 1.7;
        color: var(--text);
        background: var(--bg);
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
    }

    h1, h2 {
        font-weight: 600;
        margin-bottom: 16px;
        color: var(--text);
    }

    p {
        margin-bottom: 18px;
        color: var(--muted);
    }

    a {
        color: #79b7ff !important;
    }

    /* Standard media block */
    .media-block {
        display: flex;
        align-items: center;
        gap: 22px;
        margin: 34px 0;
        padding: 18px;
        border-radius: 14px;
        background: var(--panel);
        border: 1px solid var(--border);
    }

    .media-block img {
        width: 250px;
        aspect-ratio: 16/9;
        object-fit: cover;
        border-radius: 10px;
        border: 1px solid var(--border);
        flex-shrink: 0;
        transition: opacity 0.2s;
    }

    .media-block img:hover {
        opacity: 0.85;
    }

    .media-block p {
        margin: 0;
        flex: 1;
    }

    /* Reverse media layout */
    .reverse {
        flex-direction: row-reverse;
    }

    /* Dual-image block (clean, even layout) */
    .media-dual {
        display: flex;
        justify-content: space-between;
        align-items: center;
        gap: 22px;
        margin: 34px 0;
        padding: 20px;
        border-radius: 14px;
        background: var(--panel);
        border: 1px solid var(--border);
    }

    .media-dual img {
        width: 48%;
        aspect-ratio: 16 / 9;
        object-fit: cover;
        border-radius: 12px;
        border: 1px solid var(--border);
        transition: opacity 0.2s;
    }

    .media-dual img:hover {
        opacity: 0.85;
    }

    /* Mobile layout fixes */
    @media(max-width: 750px) {
        .media-block,
        .reverse {
            flex-direction: column;
        }
        .media-dual {
            flex-direction: column;
        }
        .media-dual img {
            width: 100%;
        }
    }

    /* Conclusion block */
    .conclusion {
        margin-top: 50px;
        padding: 22px;
        background: var(--panel);
        border: 1px solid var(--border);
        border-radius: 14px;
    }
</style>

</head>

<body>

<header class="header">
    <nav class="nav">
      <a href="../index.html">Home</a>
      <a href="../about.html">About</a>
      <a href="../links.html">Links</a>
    </nav>
</header>

<h1>My First Steps Into Machine Learning</h1>

<p><i>Note: all images in this post are clickable links to the videos that guided each part of my journey.</i></p>

<p>
Two weeks ago, my Algorithms professor suggested I explore machine learning and AI. Until then, I
only had a general idea of what these fields were—important, fast-growing, and extremely technical.
Once I began learning, I quickly realized how much depth there was behind the buzzwords.
</p>

<!-- ====================================================== -->
<!-- SECTION 1 — Andrew Ng (Correct thumbnail)               -->
<!-- ====================================================== -->

<h2>Building Foundational Knowledge</h2>

<div class="media-block reverse">
    <p>
    My first real exposure came from Andrew Ng’s “Machine Learning Specialization,” which introduced
    foundational concepts like gradient descent, cost functions, decision boundaries, and
    regularization. What stood out to me was how mathematical ideas became intuitive once they were
    explained clearly. It gave me the theoretical base I needed before touching any code.
    </p>

    <a href="https://www.youtube.com/watch?v=aircAruvnKk" target="_blank">
        <img src="https://i.ytimg.com/vi/aircAruvnKk/hqdefault.jpg" alt="Andrew Ng ML Course">
    </a>
</div>

<!-- ====================================================== -->
<!-- SECTION 2 — Dual-image block (fixed clean layout)       -->
<!-- ====================================================== -->

<h2>Understanding Neural Networks Visually</h2>

<p>
After grasping the core math, I needed intuition—something that would let me “see” what a neural
network is doing. Coding Train and 3Blue1Brown filled that gap perfectly. Their animated explanations
showed how activations move through layers, how weights shift during training, and how
backpropagation actually works.
</p>

<div class="media-dual">
    <a href="https://www.youtube.com/watch?v=ntKn5TPHHAk" target="_blank">
        <img src="https://i.ytimg.com/vi/ntKn5TPHHAk/hqdefault.jpg" alt="Coding Train Neural Network">
    </a>

    <a href="https://www.youtube.com/watch?v=aircAruvnKk" target="_blank">
        <img src="https://i.ytimg.com/vi/aircAruvnKk/hqdefault.jpg" alt="3Blue1Brown Neural Network">
    </a>
</div>

<p>
This stage transformed machine learning from an abstract topic into something I could mentally
simulate. I understood not just *what* was happening, but *why*. That shift—gaining intuition rather
than memorizing steps—is what really pulled me in.
</p>

<!-- ====================================================== -->
<!-- SECTION 3 — PyTorch + freeCodeCamp + MLP inspiration     -->
<!-- ====================================================== -->

<h2>Learning PyTorch and Building My First Models</h2>

<div class="media-block">
    <p>
    Moving into PyTorch was the turning point. I followed freeCodeCamp’s PyTorch course and learned how
    tensors work, how to build modules, how optimizers interact with gradients, and why shape mismatches
    break everything. Writing training loops by hand taught me what happens under the hood—nothing felt
    like a black box anymore.
    </p>

    <a href="https://www.youtube.com/watch?v=V_xro1bcAuA" target="_blank">
        <img src="https://i.ytimg.com/vi/V_xro1bcAuA/hqdefault.jpg" alt="PyTorch MLP Tutorial">
    </a>
</div>

<p>
As I built my first multilayer perceptron (MLP), I learned practical lessons that every beginner
encounters: how the wrong learning rate can collapse training, why initialization matters, and what a
loss curve is actually telling you. Understanding these ideas deeply—not just copying code—made me
feel like I was truly *doing* machine learning.
</p>

<p>
But the moment that really inspired me was recreating a shallow neural network from scratch, watching
it learn in real time. That experience showed me that machine learning isn't magic—it’s engineering,
mathematics, and iteration.
</p>

<!-- ====================================================== -->
<!-- CONCLUSION — Unchanged                                  -->
<!-- ====================================================== -->

<div class="conclusion">
    <p>
    I have detailed reports of the projects on my GitHub page for both my 
    <a href="#" target="_blank">Housing Prices Predictor</a> 
    and my 
    <a href="#" target="_blank">Diabetes Classification Model</a>. 
    The key take-away is this: by starting with small, focused projects you can set building blocks for larger, cooler ones.
    </p>

    <p>
    Stay tuned.<br>
    <strong>Charlie Gottschalk</strong>
    </p>

    <p><i>Written on December 5, 2025</i></p>
</div>

</body>
</html>
