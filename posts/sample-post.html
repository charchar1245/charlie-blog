<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>My First Steps Into Machine Learning</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="../style.css">

<style>
    body {
        max-width: 820px;
        margin: 40px auto;
        padding: 0 24px;
        line-height: 1.7;
        color: var(--text);
        background: var(--bg);
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
    }

    h1, h2 {
        font-weight: 600;
        margin-bottom: 16px;
        color: var(--text);
    }

    p {
        margin-bottom: 18px;
        color: var(--muted);
    }

    a {
        color: #79b7ff !important;
    }

    /* Standard media block (used for all thumbnails now) */
    .media-block {
        display: flex;
        align-items: center;
        gap: 22px;
        margin: 34px 0;
        padding: 18px;
        border-radius: 14px;
        background: var(--panel);
        border: 1px solid var(--border);
    }

    .media-block img {
        width: 250px;
        height: auto;
        border-radius: 10px;
        border: 1px solid var(--border);
        flex-shrink: 0;
        transition: opacity 0.2s;
    }

    .media-block img:hover {
        opacity: 0.85;
    }

    .media-block p {
        margin: 0;
        flex: 1;
    }

    /* Conclusion block */
    .conclusion {
        margin-top: 50px;
        padding: 22px;
        background: var(--panel);
        border: 1px solid var(--border);
        border-radius: 14px;
    }

    @media(max-width: 750px) {
        .media-block {
            flex-direction: column;
            text-align: left;
        }

        .media-block img {
            width: 100%;
        }
    }
</style>

</head>

<body>

<header class="header">
    <nav class="nav">
      <a href="../index.html">Home</a>
      <a href="../about.html">About</a>
      <a href="../links.html">Links</a>
    </nav>
</header>

<h1>My First Steps Into Machine Learning</h1>

<p><i>Note: all images in this post are clickable links to the videos that guided each part of my journey.</i></p>

<p>
Two weeks ago, my Algorithms professor suggested I explore machine learning and AI. Until then, I
only had a general idea of what these fields were. After around two weeks of learning and building projects, I now have a solid grasp on how this technology works, and I will share with you how I was able to learn it.
</p>

<!-- ====================================================== -->
<!-- SECTION 1 — Andrew Ng                                  -->
<!-- ====================================================== -->

<h2>Building Foundational Knowledge</h2>

<div class="media-block reverse">
    <p>
    My first real exposure came from Andrew Ng’s “Machine Learning Specialization,” which introduced
    foundational concepts like gradient descent, cost functions, decision boundaries, and
    regularization. What stood out to me was how mathematical ideas became intuitive once they were
    explained clearly. It gave me the theoretical base I needed before touching any code.
    </p>

    <a href="https://www.youtube.com/watch?v=aircAruvnKk" target="_blank">
        <img src="sddefault.jpg" alt="Andrew Ng ML Course">
    </a>
</div>

<!-- ====================================================== -->
<!-- SECTION 2 — Two separate media-block rows              -->
<!-- ====================================================== -->

<h2>Understanding Neural Networks Visually</h2>

<p>
After grasping the core math, I needed intuition—something that would let me “see” what a neural
network is doing. Coding Train and 3Blue1Brown filled that gap perfectly. Their animated explanations
showed how activations move through layers, how weights shift during training, and how
backpropagation actually works.
</p>

<div class="media-block">
    <a href="https://www.youtube.com/watch?v=ntKn5TPHHAk" target="_blank">
        <img src="https://i.ytimg.com/vi/ntKn5TPHHAk/hqdefault.jpg" alt="Coding Train Neural Network">
    </a>
    <p>
        <strong>Coding Train — Perceptron & Neural Networks</strong><br>
        This video helped me visualize how simple neural networks learn and update weights step-by-step.
    </p>
</div>

<div class="media-block">
    <a href="https://www.youtube.com/watch?v=aircAruvnKk" target="_blank">
        <img src="https://i.ytimg.com/vi/aircAruvnKk/hqdefault.jpg" alt="3Blue1Brown Neural Network">
    </a>
    <p>
        <strong>3Blue1Brown — Neural Networks Explained</strong><br>
        The animations here made backpropagation and activation functions feel intuitive in a way that
        textbooks simply cannot replicate.
    </p>
</div>

<p>
This stage transformed machine learning from an abstract topic into something I could mentally
simulate. I understood not just *what* was happening, but *why*. 
</p>

<!-- ====================================================== -->
<!-- SECTION 3 — PyTorch                                    -->
<!-- ====================================================== -->

<h2>Learning PyTorch and Building My First Models</h2>

<div class="media-block">
    <a href="https://www.youtube.com/watch?v=V_xro1bcAuA" target="_blank">
        <img src="https://i.ytimg.com/vi/V_xro1bcAuA/hqdefault.jpg" alt="PyTorch MLP Tutorial">
    </a>
    <p>
    Moving into PyTorch was the turning point. I followed freeCodeCamp’s PyTorch course and learned how
    tensors work, how to build modules, how optimizers interact with gradients, and why shape mismatches
    break everything. Writing training loops by hand taught me what happens under the hood—nothing felt
    like a black box anymore.
    </p>
</div>

<p>
This phase is still quite tricky, as I had to really adjust to visualizing all these theoretical models strictly through lines of code.
However, once you familiarize yourself with the PyTorch and Pandas libraries, you will find this switch is not as intimidating as it seems.
</p>

<p>
As I built my first multilayer perceptron (MLP), I learned practical lessons that every beginner
encounters: how the wrong learning rate can collapse training, why initialization matters, and what a
loss curve is actually telling you. Understanding these ideas deeply made me
feel like I was truly *doing* machine learning.
</p>

<p>
But the moment that really inspired me was recreating a shallow neural network from scratch, watching
it learn in real time. That experience showed me that machine learning isn't magic, it’s engineering,
mathematics, and most importantly, trial and error.
</p>

<!-- ====================================================== -->
<!-- CONCLUSION                                             -->
<!-- ====================================================== -->

<div class="conclusion">
    <p>
    I have detailed reports of the projects on my GitHub page for both my 
    <a href="https://github.com/charchar1245/CHARLIE_PORTFOLIO/blob/main/projects/housing-prices/README.md" target="_blank">Housing Prices Predictor</a> 
    and my 
    <a href="https://github.com/charchar1245/CHARLIE_PORTFOLIO/blob/main/projects/diabetes-classification-model/README.md" target="_blank">Diabetes Classification Model</a>. 
    The key take-away is this: by starting with small, focused projects you can set building blocks for larger, cooler ones.
    </p>

    <p>
    Stay tuned.<br>
    <strong>Charlie Gottschalk</strong>
    </p>

    <p><i>Written on December 5, 2025</i></p>
</div>

</body>
</html>

